{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of the analysis is to produce a model which can predict loan approval. For the purposes of this data cleaning notebook, we want to define an account level of granularity to use in our analysis notebook.\n",
    "\n",
    "The dataset is from a Czech bank and their client information is separated into 8 tables:\n",
    "\n",
    "- **account** - static characteristics of an account\n",
    "- **client** - characteristics of a client\n",
    "- **disposition** - relationship between a client and their account\n",
    "- **permanent order** characteristics of a payment\n",
    "- **transaction** - transaction on an account\n",
    "- **loan** - loan granted for a given account\n",
    "- **credit card** - credit card issued to an account\n",
    "- **demographic** - demographic characteristics of a district\n",
    "\n",
    "More information on this dataset can be found here: \n",
    "[Financial Dataset](https://sorry.vse.cz/~berka/challenge/pkdd1999/berka.htm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "# import seaborn as sns\n",
    "# import pymysql\n",
    "# import datetime\n",
    "plt.style.use('fivethirtyeight')\n",
    "#plt.style.use('default')\n",
    "# from functools import reduce\n",
    "pd.set_option('display.max_columns',None)\n",
    "pd.set_option('display.min_rows', None)\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_account = pd.read_csv('csv_files/raw_csv/df_account.csv', low_memory = False) \n",
    "df_client = pd.read_csv('csv_files/raw_csv/df_client.csv', low_memory = False)\n",
    "df_disp = pd.read_csv('csv_files/raw_csv/df_disp.csv', low_memory = False)\n",
    "df_order = pd.read_csv('csv_files/raw_csv/df_order.csv', low_memory = False)\n",
    "df_trans = pd.read_csv('csv_files/raw_csv/df_trans.csv', low_memory = False)\n",
    "df_loan = pd.read_csv('csv_files/raw_csv/df_loan.csv', low_memory = False)\n",
    "df_card = pd.read_csv('csv_files/raw_csv/df_card.csv', low_memory = False)\n",
    "df_district = pd.read_csv('csv_files/raw_csv/df_district.csv', low_memory = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 8 different raw CSV files that we need to manipulate. I decided to create this function to give an overview of a data frame as we'll be investigating several dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_overview(df):\n",
    "    \n",
    "    '''\n",
    "    Outputs an overview of the dataframe:\n",
    "    - Sample of dataframe\n",
    "    - Shape\n",
    "    - Data types\n",
    "    - Missing values (%)\n",
    "    - Descriptive statistics\n",
    "    '''\n",
    "    print('\\nShape of dataframe:\\n')\n",
    "    print(f'{df.shape[0]} rows | {df.shape[1]} columns')\n",
    "    print('-' * 42)\n",
    "    \n",
    "    print('\\nSample of dataframe:\\n')\n",
    "    print(df.head())\n",
    "    print('-' * 42)\n",
    "    \n",
    "    print('\\nData types of dataframe:\\n')\n",
    "    print(df.dtypes)\n",
    "    print('-' * 42)\n",
    "    \n",
    "    print('\\nMissing values by % in dataframe\\n')\n",
    "    print(df.isnull().sum()*100/df.shape[0])\n",
    "    print('-' * 42)\n",
    "    \n",
    "    print('\\nDecriptive statistics of dataframe:\\n')\n",
    "    print(df.describe())\n",
    "    print('-' * 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Shape of dataframe:\n",
      "\n",
      "4500 rows | 4 columns\n",
      "------------------------------------------\n",
      "\n",
      "Sample of dataframe:\n",
      "\n",
      "   account_id  district_id         frequency        date\n",
      "0           1           18  POPLATEK MESICNE  1995-03-24\n",
      "1           2            1  POPLATEK MESICNE  1993-02-26\n",
      "2           3            5  POPLATEK MESICNE  1997-07-07\n",
      "3           4           12  POPLATEK MESICNE  1996-02-21\n",
      "4           5           15  POPLATEK MESICNE  1997-05-30\n",
      "------------------------------------------\n",
      "\n",
      "Data types of dataframe:\n",
      "\n",
      "account_id      int64\n",
      "district_id     int64\n",
      "frequency      object\n",
      "date           object\n",
      "dtype: object\n",
      "------------------------------------------\n",
      "\n",
      "Missing values by % in dataframe\n",
      "\n",
      "account_id     0.0\n",
      "district_id    0.0\n",
      "frequency      0.0\n",
      "date           0.0\n",
      "dtype: float64\n",
      "------------------------------------------\n",
      "\n",
      "Decriptive statistics of dataframe:\n",
      "\n",
      "         account_id  district_id\n",
      "count   4500.000000  4500.000000\n",
      "mean    2786.067556    37.310444\n",
      "std     2313.811984    25.177217\n",
      "min        1.000000     1.000000\n",
      "25%     1182.750000    13.000000\n",
      "50%     2368.000000    38.000000\n",
      "75%     3552.250000    60.000000\n",
      "max    11382.000000    77.000000\n",
      "------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "df_overview(df_account)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's convert to English for better understanding.\n",
    "df_account['frequency'].replace('POPLATEK MESICNE', 'monthly', inplace=True)\n",
    "df_account['frequency'].replace('POPLATEK TYDNE', 'weekly', inplace=True)\n",
    "df_account['frequency'].replace('POPLATEK PO OBRATU', 'after_trans', inplace=True)\n",
    "df_account.rename(columns = {'frequency':'stmt_frq'}, inplace=True) #statement frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Frequency of an account is defined as: \"frequency of issuance of statements\"\n",
    "- \"POPLATEK MESICNE\" stands for monthly issuance\n",
    "- \"POPLATEK TYDNE\" stands for weekly issuance\n",
    "- \"POPLATEK PO OBRATU\" stands for issuance after transaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert date to a datetime type variable\n",
    "df_account['date'] = pd.to_datetime(df_account['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_client.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_client.isnull().sum()*100/df_client.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_client.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in dataframes:\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert date to a datetime type variable\n",
    "df_client['birth_date'] = pd.to_datetime(df_client['birth_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = [df1, df2]\n",
    "\n",
    "for i in df_list:\n",
    "\n",
    "   i = i.rename(columns={\n",
    "  '1':'a',\n",
    "  '2':'b',\n",
    "  '3':'c', ...})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_disp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in range(raw_file_names):\n",
    "    name = dataframes[name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_disp.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[dataframes[name] for name in raw_file_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_order.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {frame: pd.DataFrame() for frame in dataframes}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_order.isnull().sum()*100/df_order.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in dataframes:\n",
    "    \n",
    "dataframes[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_order.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- \"POJISTNE\" stands for insurance payment\n",
    "- \"SIPO\" stands for household\n",
    "- \"LEASING\" stands for leasing\n",
    "- \"UVER\" stands for loan payment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's convert k_symbol to English\n",
    "df_order['k_symbol'].replace('POJISTNE', 'insurance', inplace=True)\n",
    "df_order['k_symbol'].replace('SIPO', 'household', inplace=True)\n",
    "df_order['k_symbol'].replace('LEASING', 'leasing', inplace=True)\n",
    "df_order['k_symbol'].replace('UVER', 'loan', inplace=True)\n",
    "df_order['k_symbol'].replace(np.nan, 'unknown', inplace=True)\n",
    "df_order.rename(columns = {'k_symbol':'order_payment_type'}, inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trans.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trans.isnull().sum()*100/df_trans.shape[0]\n",
    "\n",
    "#bank & account have over 70% of rows missing - won't be using"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trans['operation'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trans['k_symbol'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trans.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert date to a datetime type variable\n",
    "df_trans['date'] = pd.to_datetime(df_trans['date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`type` - type of transaction\n",
    "- \"PRIJEM\" stands for credit\n",
    "- \"VYDAJ\" stands for withdrawal\n",
    "\n",
    "`operation` - mode of transaction\n",
    "- \"VYBER KARTOU\" credit card withdrawal\n",
    "- \"VKLAD\" credit in cash\n",
    "- \"PREVOD Z UCTU\" collection from another bank\n",
    "- \"VYBER\" withdrawal in cash\n",
    "- \"PREVOD NA UCET\" remittance to another bank\n",
    "\n",
    "`k_symbol` - characterization of transaction\n",
    "- \"POJISTNE\" stands for insurrance payment\n",
    "- \"SLUZBY\" stands for payment for statement\n",
    "- \"UROK\" stands for interest credited\n",
    "- \"SANKC. UROK\" sanction interest if negative balance\n",
    "- \"SIPO\" stands for household\n",
    "- \"DUCHOD\" stands for old-age pension\n",
    "- \"UVER\" stands for loan payment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace names for type\n",
    "df_trans['type'].replace('PRIJEM', 'credit', inplace=True)\n",
    "df_trans['type'].replace('VYDAJ', 'withdrawal', inplace=True)\n",
    "df_trans.rename(columns = {'type':'trans_type'}, inplace=True) \n",
    "\n",
    "# Replace names for operation\n",
    "df_trans['operation'].replace('VYBER KARTOU', 'cc_withdrawal', inplace=True) #credit card withdrawal\n",
    "df_trans['operation'].replace('VKLAD', 'c_cash', inplace=True) #credit in cash\n",
    "df_trans['operation'].replace('PREVOD Z UCTU', 'col_bank', inplace=True) #collection from another bank\n",
    "df_trans['operation'].replace('VYBER', 'withdrawal_c', inplace=True) #withdrawal in cash\n",
    "df_trans['operation'].replace('PREVOD NA UCET', 'remittance', inplace=True) #withdrawal in cash\n",
    "df_trans['operation'].replace(np.nan, 'unknown', inplace=True)\n",
    "\n",
    "# Replace names for k_symbol\n",
    "df_trans['k_symbol'].replace('POJISTNE', 'insurance', inplace=True) \n",
    "df_trans['k_symbol'].replace('SLUZBY', 'statement', inplace=True) \n",
    "df_trans['k_symbol'].replace('UROK', 'int_cred', inplace=True) #interest credited\n",
    "df_trans['k_symbol'].replace('SANKC. UROK', 'sanc_int', inplace=True) #sanction interest if negative balance\n",
    "df_trans['k_symbol'].replace('SIPO', 'household', inplace=True) \n",
    "df_trans['k_symbol'].replace('DUCHOD', 'pension', inplace=True) \n",
    "df_trans['k_symbol'].replace('UVER', 'loan', inplace=True) \n",
    "df_trans['k_symbol'].replace(np.nan, 'unknown', inplace=True)\n",
    "df_trans['k_symbol'].replace(' ', 'unknown', inplace=True)\n",
    "df_trans.rename(columns = {'k_symbol':'trans_payment_type'}, inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_loan.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_loan.isnull().sum()*100/df_loan.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_loan.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert date to a datetime type variable\n",
    "df_loan['date'] = pd.to_datetime(df_loan['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename loan columns\n",
    "df_loan = df_loan.rename(columns={'amount': 'loan_amount', 'duration':'loan_duration', 'payments':'monthly_loan_payment', 'status':'loan_status'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_card.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_card.isnull().sum()*100/df_card.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_card.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_card['issued'] = pd.to_datetime(df_card['issued'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_district.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_district.isnull().sum()*100/df_card.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_district.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_district = df_district.rename(columns={'A2':'district_name', \n",
    "                                          'A3':'region', \n",
    "                                          'A4':'population', \n",
    "                                          'A5':'nmu_lt499',\n",
    "                                          'A6':'nmu_500to1999', \n",
    "                                          'A7':'nmu_2000to9999', \n",
    "                                          'A8':'nmu_gt10000',\n",
    "                                          'A9':'n_cty', \n",
    "                                          'A10':'ratio_urban', \n",
    "                                          'A11':'avg_salary', \n",
    "                                          'A12':'unemp_95', \n",
    "                                          'A13': 'unemp_96',\n",
    "                                          'A14':'nentrep_p1000', \n",
    "                                          'A15':'ncrimes_95', \n",
    "                                          'A16':'ncrimes_96'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time to merge different dateframes\n",
    "\n",
    "df_final = pd.merge(df_account, df_disp, on = 'account_id') #shape: 5369, 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = pd.merge(df_final, df_district, on = 'district_id') # shape: 5369, 22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = pd.merge(df_final, df_client, on = 'client_id') #shape: 5369, 25\n",
    "\n",
    "#can drop one of the district_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = pd.merge(df_final, df_card, on='disp_id', how='outer', suffixes=('_disp','_card')) #shape: 5369, 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = pd.merge(df_final, df_loan, on='account_id', how='inner', suffixes=('_account','_loan')) #shape: 827, 34\n",
    "\n",
    "#We only keep the accounts with loans "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_final['client_id'].unique()) \n",
    "\n",
    "# There are 827 unique clients with loans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_final['account_id'].unique()) \n",
    "\n",
    "# This makes sense as the semi anonymized dataset contains 606 successful and 76 not successful loans."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trans.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trans_account = pd.merge(df_trans, df_final[['account_id','date_loan']], on = 'account_id') \n",
    "\n",
    "#shape: 233627, 11 transactions for accounts with loans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trans_account.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop duplicate transactions\n",
    "df_trans_account = df_trans_account.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trans_account.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the difference between the date of the loan and the date of the transaction\n",
    "df_trans_account['date_diff'] = (df_trans_account['date_loan'] - df_trans_account['date']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trans_account.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trans_account.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's drop transactions that occured after the loan date\n",
    "df_trans_account.drop(df_trans_account[df_trans_account['date_diff'] < datetime.timedelta(0)].index, inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trans_account.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trans_type_counts = df_trans_account.groupby('account_id')['trans_type'].value_counts().to_frame()\n",
    "df_operation_counts = df_trans_account.groupby('account_id')['operation'].value_counts().to_frame()\n",
    "df_payment_type_counts = df_trans_account.groupby('account_id')['trans_payment_type'].value_counts().to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trans_type_counts.index = df_trans_type_counts.index.set_names(['account_id', 'transaction_type'])\n",
    "df_operation_counts.index = df_operation_counts.index.set_names(['account_id', 'operation_type'])\n",
    "df_payment_type_counts.index = df_payment_type_counts.index.set_names(['account_id', 'payment_type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trans_type_counts.reset_index(inplace=True)\n",
    "df_operation_counts.reset_index(inplace=True)\n",
    "df_payment_type_counts.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trans_type_counts = df_trans_type_counts.pivot(index='account_id', columns='transaction_type', values='trans_type').fillna(0).reset_index(inplace=False)\n",
    "df_operation_counts = df_operation_counts.pivot(index='account_id', columns='operation_type', values='operation').fillna(0).reset_index(inplace=False)\n",
    "df_payment_type_counts = df_payment_type_counts.pivot(index='account_id', columns='payment_type', values='trans_payment_type').fillna(0).reset_index(inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trans_type_counts.columns = ['num_trans_' + str(col) for col in df_trans_type_counts.columns]\n",
    "df_operation_counts.columns = ['num_ops_' + str(col) for col in df_operation_counts.columns]\n",
    "df_payment_type_counts.columns = ['num_pay_' + str(col) for col in df_payment_type_counts.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trans_type_counts.rename(columns={'num_trans_account_id':'account_id'}, inplace=True)\n",
    "df_operation_counts.rename(columns={'num_ops_account_id':'account_id'}, inplace=True)\n",
    "df_payment_type_counts.rename(columns={'num_pay_account_id':'account_id'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_payment_type_counts['account_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create new transaction counts data frame \n",
    "counts_dataframes = [df_trans_type_counts, df_operation_counts, df_payment_type_counts]\n",
    "df_counts = reduce(lambda left,right: pd.merge(left,right,on='account_id'), counts_dataframes)#shape: 682,17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = pd.merge(df_final, df_counts, on = 'account_id') #shape: 827, 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most lenders ask to see at least two-three months' worth of statements before they issue you a loan.\n",
    "\n",
    "Let's take a look at the account balance before the loan date for the past 3 months."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trans_account_copy = df_trans_account.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trans_account_copy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's take a look at transactions within different time frames upto 3 months\n",
    "df_trans_account_30 = df_trans_account_copy.copy()\n",
    "df_trans_account_60 = df_trans_account_copy.copy()\n",
    "df_trans_account_90 = df_trans_account_copy.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reducing transactions by months (30, 60, 90 days)\n",
    "df_trans_account_30.drop(df_trans_account_30[df_trans_account_30['date_diff'] > datetime.timedelta(30)].index, inplace=True)\n",
    "df_trans_account_60.drop(df_trans_account_60[df_trans_account_60['date_diff'] > datetime.timedelta(60)].index, inplace=True)\n",
    "df_trans_account_90.drop(df_trans_account_90[df_trans_account_90['date_diff'] > datetime.timedelta(90)].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trans_account_30.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trans_account_90.shape\n",
    "\n",
    "#Makes sense as there are more transaction with more time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mon_1_balance = df_trans_account_30.groupby('account_id')['balance'].agg(['min','max','mean','count']).reset_index()\n",
    "mon_2_balance = df_trans_account_60.groupby('account_id')['balance'].agg(['min','max','mean','count']).reset_index()\n",
    "mon_3_balance = df_trans_account_90.groupby('account_id')['balance'].agg(['min','max','mean','count']).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mon_1_balance.rename(columns = {'min':'min1','max':'max1','mean':'mean1','count':'count1'}, inplace=True)\n",
    "mon_2_balance.rename(columns = {'min':'min2','max':'max2','mean':'mean2','count':'count2'}, inplace=True)\n",
    "mon_3_balance.rename(columns = {'min':'min3','max':'max3','mean':'mean3','count':'count3'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create new client data frame with different balance statistics for different time frames\n",
    "balance_dataframes = [df_final, mon_1_balance, mon_2_balance, mon_3_balance]\n",
    "df_final = reduce(lambda left,right: pd.merge(left,right,on='account_id'), balance_dataframes)#shape:827,62 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's focus on the owners of the account but we'll keep a count if there are multiple people on an account \n",
    "\n",
    "df_num_clients = df_final.groupby('account_id', as_index=False)['type_disp'].count().rename(columns={'type_disp':'num_clients'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_num_clients.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = pd.merge(df_final, df_num_clients, on = 'account_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final_owner = df_final[df_final['type_disp']=='OWNER']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final_owner.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final_owner.to_csv('df_final_owner.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "loan_venv",
   "language": "python",
   "name": "loan_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
